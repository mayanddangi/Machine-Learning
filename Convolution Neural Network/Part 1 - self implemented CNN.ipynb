{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bd4b06",
   "metadata": {},
   "source": [
    "### Import neccesary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58160721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5eeaf",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282a0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data/cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4beccec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    X = dict[b'data']\n",
    "    y = np.array(dict[b'labels'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b616016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for b in range(1,6):\n",
    "    f = train_dir+'data_batch_'+str(b)\n",
    "    X, y = unpickle(f)\n",
    "    xs.append(X)\n",
    "    ys.append(y)\n",
    "Xtr = np.concatenate(xs)\n",
    "Ytr = np.concatenate(ys)\n",
    "del X, y\n",
    "del xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bc4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = Xtr/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c973da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c02d7",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0e4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.cache = X\n",
    "        return np.maximum(0, X)\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        X = self.cache\n",
    "#         print(f'dim of X relu:{X.shape}, dim of dY relu: {dY.shape}')\n",
    "        dY[X <= 0] = 0\n",
    "        return dY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704a89d",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a17b2",
   "metadata": {},
   "source": [
    "### Class definition\n",
    "Class `Conv2D` implements a 2D convolution layer\n",
    "\n",
    "#### Constructor\n",
    "The `Conv2D` class has constructor with following parameters:       \n",
    "  - `in_ch` (int) : number of in channels\n",
    "  - `out_ch` (int): number of out channels\n",
    "  - `k_size` (int): dimension size of kernel\n",
    "  - `stride` (int)\n",
    "  - `padding` (string): valid or same\n",
    "\n",
    "\n",
    "#### Methods\n",
    "\n",
    "**`forward(arr_in)`**\n",
    "Computes the forward pass of the layer given an input tensor `arr_in`. Returns the output tensor and caches values needed for the backward pass.\n",
    "\n",
    "**`backward(out_grad)`**\n",
    "Computes the backward pass of the layer given the gradient of the loss with respect to the output tensor `out_grad`. Returns the gradient of the loss with respect to the input tensor.\n",
    "\n",
    "**`getGrads()`**\n",
    "Returns the weights and bias gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8444cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride = 1, padding = 'valid'):\n",
    "        self.in_ch = in_channels\n",
    "        self.out_ch = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.k_size = kernel_size\n",
    "        self.w = np.random.randn(self.k_size, self.k_size, self.in_ch, self.out_ch)/10\n",
    "#         print(self.w.shape)\n",
    "        self.bias = np.random.randn(self.out_ch)/10\n",
    "        \n",
    "    '''\n",
    "        arr_in  - input data of shape (n, h_in, w_in, in_ch)\n",
    "        weights - convolutional filter weights of shape (k_size, k_size, in_ch, out_ch)\n",
    "        out     - output feature map of shape (n, out_h, out_w, out_ch)\n",
    "        b       - bias tensor with shape (out_ch, )\n",
    "    '''\n",
    "    def forward(self, arr_in):\n",
    "        n, in_h, in_w, in_ch = arr_in.shape\n",
    "        self.arr_in0 = arr_in\n",
    "#         '''\n",
    "#             output array dimension for convolution of two matrix is given by relation:\n",
    "#                 floor((in_h+2*self.pad-self.k_size)/self.stride)+1, floor(in_w+2*self.pad-self.k_size)/self.stride)+1\n",
    "#         '''\n",
    "        if(self.padding == 'valid'):\n",
    "            self.pad = (self.k_size - 1) // 2\n",
    "            \n",
    "        else:\n",
    "            self.pad = 0\n",
    "        out_h = (in_h+2*self.pad-self.k_size)//self.stride+1\n",
    "        out_w = (in_w+2*self.pad-self.k_size)//self.stride+1\n",
    "\n",
    "#         out_h = (in_h-self.k_size)//self.stride+1\n",
    "#         out_w = (in_w-self.k_size)//self.stride+1\n",
    "    \n",
    "        \n",
    "        arr_out = np.zeros((n, out_h, out_w, self.out_ch))\n",
    "#         print(arr_out.shape)\n",
    "        '''\n",
    "            np.pad(array, pad_width)\n",
    "                pad_width takes tuple of tuple, length of tuple equal to the axis in array indicating the number of pad to be added before and after of each axis\n",
    "            we want to add padding in the image content only\n",
    "        '''\n",
    "\n",
    "        self.arr_pad = np.pad(arr_in, pad_width =  ((0,0), (self.pad, self.pad), (self.pad, self.pad), (0,0)))\n",
    "#         print(self.arr_pad)\n",
    "        # Convolution starts\n",
    "        for i in range(0, out_h):\n",
    "            for j in range(0, out_w):\n",
    "#                 print(self.w.shape)\n",
    "                temp = self.arr_pad[:,i*self.stride:self.k_size+i*self.stride,j*self.stride:self.k_size+j*self.stride,:,np.newaxis]*self.w[np.newaxis,:,:,:,:]\n",
    "#                 print(np.sum(temp,axis=(1,2,3)).shape)\n",
    "#                 print(arr_out[:,i,j,:].shape)\n",
    "                arr_out[:,i,j,:] = np.sum(temp,axis=(1,2,3))\n",
    "                \n",
    "        return arr_out\n",
    "    \n",
    "    def backward(self, out_grad, lr=0.01):\n",
    "        self.out_grad = out_grad\n",
    "        n, hg_out, wg_out, _ = out_grad.shape\n",
    "        n, h_in, w_in, _ = self.arr_in0.shape\n",
    "        arr_in0_pad = self.arr_pad\n",
    "#         print(arr_in0_pad.shape)\n",
    "        self.in_grad = np.zeros(arr_in0_pad.shape)\n",
    "        self.kernel_grad = np.zeros(self.w.shape)\n",
    "        \n",
    "        for i in range(0, hg_out):\n",
    "            for j in range(0, wg_out):\n",
    "                self.in_grad[:,i*self.stride:self.k_size+i*self.stride,j*self.stride:self.k_size+j*self.stride,:] += np.sum(self.w[np.newaxis, :, :, :, :]*out_grad[:, i:i+1, j:j+1, np.newaxis, :],axis=4)             \n",
    "                self.kernel_grad += np.sum(arr_in0_pad[:, i*self.stride:i*self.stride+self.k_size, j*self.stride:j*self.stride+self.k_size, :, np.newaxis]*(out_grad[:, i:i+1, j:j+1, np.newaxis, :])/n,axis=0)\n",
    "                \n",
    "        self.w -= lr*self.kernel_grad/n\n",
    "        self.bias -= lr*np.sum(out_grad/n, axis = (0,1,2))\n",
    "        self.dbias = np.sum(out_grad, axis = (0,1,2))/n\n",
    "#         self.kernel_grad = self.kernel_grad/n\n",
    "        \n",
    "        return self.in_grad[:, self.pad:self.pad+h_in, self.pad:self.pad+w_in, :]\n",
    "    \n",
    "    def update_weights(self, w, b):\n",
    "        self.w = w\n",
    "        self.bias = b\n",
    "        \n",
    "    def getGrads(self):\n",
    "        return self.kernel_grad, self.dbias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe477b",
   "metadata": {},
   "source": [
    "### Class definition\n",
    "Class `MaxPool2D` implements a 2D maxpooling layer\n",
    "\n",
    "#### Constructor\n",
    "The `MaxPool2D` class has constructor with following parameters:       \n",
    "  - `k_size` (int) : kernel_size\n",
    "\n",
    "\n",
    "#### Methods\n",
    "\n",
    "**`forward(arr_in)`**\n",
    "Performs a 2D max pooling operation on the input tensor with a given kernel size and stride\n",
    "\n",
    "**`backward(out_grad)`**\n",
    "The backward pass of MaxPool2d function takes as input the gradient tensor of the loss function with respect to the output of MaxPool2d, out_grad, and computes the gradient of the loss function with respect to the input of MaxPool2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15b1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, kernel_size):\n",
    "        self.k_size = kernel_size\n",
    "        self.cache = None\n",
    "    def forward(self, arr_in, stride=1):\n",
    "#         print(arr_in.shape)\n",
    "        self.stride = stride\n",
    "        n, in_h, in_w, in_ch = arr_in.shape\n",
    "\n",
    "        out_h = (in_h) // self.k_size\n",
    "        out_w = (in_w) // self.k_size\n",
    "        \n",
    "        arr_out = np.max(arr_in.reshape(n, out_h, self.k_size, out_w, self.k_size, in_ch), axis=(2, 4))\n",
    "\n",
    "        self.cache = arr_in, arr_out\n",
    "        return arr_out\n",
    "    \n",
    "    def backward(self, out_grad):\n",
    "        arr_in, arr_out = self.cache\n",
    "        in_grad = (arr_in == np.repeat(np.repeat(arr_out, self.k_size, axis = 1), self.k_size, axis = 2))*(np.repeat(np.repeat(out_grad, self.k_size, axis = 1), self.k_size, axis = 2))\n",
    "        return in_grad        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e961dc2",
   "metadata": {},
   "source": [
    "### Class definition\n",
    "Class `Linear` implements fully connected neural network\n",
    "\n",
    "#### Constructor\n",
    "The `Linear` class has constructor with following parameters:       \n",
    "  - `input_size` (int)\n",
    "  - `output_size`(int)\n",
    "  - `w` (np array) : weights\n",
    "  - `b` (np array) : bias\n",
    "\n",
    "#### Methods\n",
    "\n",
    "**`forward(arr_in)`**\n",
    "Performs a forward pass through the layer.\n",
    "\n",
    "**`backward(out_grad)`**\n",
    "Performs a backward pass through the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4201238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.w = np.random.randn(input_size, output_size) /10\n",
    "        self.b = np.random.randn(1, output_size)/10\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, arr_in):\n",
    "        self.cache = arr_in\n",
    "        return np.dot(arr_in, self.w) + self.b\n",
    "    \n",
    "    def backward(self, dY, lr=0.01):\n",
    "        arr_in = self.cache        \n",
    "        n = arr_in.shape[0]    \n",
    "        d_arr_in = np.matmul(dY/n, self.w.T)\n",
    "        self.dW = np.matmul(arr_in.T, dY/n)\n",
    "        self.db = np.sum(dY/n, axis=0, keepdims=True)\n",
    "        \n",
    "        w_old = np.array(self.w, copy = True)\n",
    "        self.w -= lr * self.dW\n",
    "        self.b -= lr * self.db\n",
    "        \n",
    "        if((self.w == w_old).all()): print(\"equal\")\n",
    "        \n",
    "        return d_arr_in\n",
    "    \n",
    "    def update_weights(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def getGrads(self):\n",
    "        return self.dW, self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7604f13",
   "metadata": {},
   "source": [
    "### Class definition\n",
    "Class `Flat` converts the shape of input between fully connected and convolution network\n",
    "\n",
    "#### Methods\n",
    "\n",
    "**`forward(arr_in)`**\n",
    "Flatten 4D tensor to 1D array\n",
    "\n",
    "**`backward(out_grad)`**\n",
    "convert 1D array back to 4D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600514aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flat():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "        \n",
    "    def forward(self, arr_in):\n",
    "#         print(arr_in.shape)\n",
    "        self.shape = arr_in.shape\n",
    "        return np.reshape(arr_in.ravel(), (arr_in.shape[0], -1))\n",
    "    \n",
    "    def backward(self, out_grad):\n",
    "        return np.reshape(out_grad, self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9f724",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da81154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam_opt:\n",
    "    def __init__(self, lr, beta1 = 0.9, beta2 = 0.99, epsilon = 1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m_c = None\n",
    "        self.v_c = None\n",
    "        self.m_f = None\n",
    "        self.v_f = None\n",
    "        self.t = 0\n",
    "        \n",
    "    def update(self, conv_layers, fc_layers):\n",
    "        self.t+=1\n",
    "        if self.m_c is None:\n",
    "            self.m_c = {}\n",
    "            self.v_c = {}\n",
    "            for i, layer in enumerate(conv_layers):\n",
    "                kernel_grad, dbias = layer.getGrads()\n",
    "                self.m_c[i] = (np.zeros_like(kernel_grad), np.zeros_like(dbias))\n",
    "                self.v_c[i] = (np.zeros_like(kernel_grad), np.zeros_like(dbias))\n",
    "        for i, layer in enumerate(conv_layers):\n",
    "            kernel_grad, dbias = layer.getGrads()\n",
    "            self.m_w, self.m_bias = self.m_c[i]\n",
    "            self.v_w, self.v_bias = self.v_c[i]\n",
    "            \n",
    "            self.m_w = self.beta1 * self.m_w + (1 - self.beta1) * kernel_grad\n",
    "            self.v_w = self.beta2 * self.v_w + (1 - self.beta2) * (kernel_grad ** 2)\n",
    "            m_hat = self.m_w / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v_w / (1 - self.beta2 ** self.t)\n",
    "            layer.w -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            \n",
    "            \n",
    "            self.m_bias = self.beta1 * self.m_bias + (1 - self.beta1) * dbias\n",
    "            self.v_bias = self.beta2 * self.v_bias + (1 - self.beta2) * (dbias ** 2)\n",
    "            m_hat = self.m_bias / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v_bias / (1 - self.beta2 ** self.t)\n",
    "            layer.bias -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            self.m_c[i] = (self.m_w, self.m_bias)\n",
    "            self.v_c[i] = (self.v_w, self.v_bias)\n",
    "            \n",
    "            \n",
    "        if self.m_f is None:\n",
    "            self.m_f = {}\n",
    "            self.v_f = {}\n",
    "            for i, layer in enumerate(fc_layers):\n",
    "                dw, dbias = layer.getGrads()\n",
    "                self.m_f[i] = (np.zeros_like(dw), np.zeros_like(dbias))\n",
    "                self.v_f[i] = (np.zeros_like(dw), np.zeros_like(dbias))\n",
    "                \n",
    "        for i, layer in enumerate(fc_layers):\n",
    "            dw, dbias = layer.getGrads()\n",
    "            self.m_w, self.m_bias = self.m_f[i]\n",
    "            self.v_w, self.v_bias = self.v_f[i]\n",
    "            \n",
    "            self.m_w = self.beta1 * self.m_w + (1 - self.beta1) * kernel_grad\n",
    "            self.v_w = self.beta2 * self.v_w + (1 - self.beta2) * (kernel_grad ** 2)\n",
    "            m_hat = self.m_w / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v_w / (1 - self.beta2 ** self.t)\n",
    "            layer.w -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            \n",
    "            \n",
    "            self.m_bias = self.beta1 * self.m_bias + (1 - self.beta1) * dbias\n",
    "            self.v_bias = self.beta2 * self.v_bias + (1 - self.beta2) * (dbias ** 2)\n",
    "            m_hat = self.m_bias / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v_bias / (1 - self.beta2 ** self.t)\n",
    "            layer.b -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            \n",
    "            self.m_f[i] = (self.m_w, self.m_bias)\n",
    "            self.v_f[i] = (self.v_w, self.v_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9694ab",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d25ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalCrossentropy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, y_pred, y_true):\n",
    "        \n",
    "        loss = -np.sum(y_true * np.log(np.clip(y_pred, 1e-20, 1 - 1e-20))) / y_pred.shape[0]        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "\n",
    "        d_y_pred = -(y_true / np.clip(y_pred, 1e-20, 1 - 1e-20)) / y_pred.shape[0]        \n",
    "        return d_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8fa8e",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6a44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2D(3, 32, 3)\n",
    "        self.pool1 = MaxPool2D(2)\n",
    "        self.conv2 = Conv2D(32, 64, 5)\n",
    "        self.pool2 = MaxPool2D(2)\n",
    "        self.conv3 = Conv2D(64, 64, 3)\n",
    "        self.fc1 = Linear(64*8*8, 64)\n",
    "#         self.fc1 = Linear(65536, 64)\n",
    "        self.fc2 = Linear(64, 10)\n",
    "        self.relu1 = ReLU()\n",
    "        self.relu2 = ReLU()\n",
    "        self.relu3 = ReLU()\n",
    "        self.relu4 = ReLU()\n",
    "        self.flatten = Flat()\n",
    "        \n",
    "        self.conv_layers = [self.conv1, self.conv2, self.conv3]\n",
    "        self.fc_layers = [self.fc1, self.fc2]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        y = self.conv1.forward(X)\n",
    "        y = self.pool1.forward(self.relu1.forward(y))        \n",
    "        y = self.pool2.forward(self.relu2.forward(self.conv2.forward(y)))\n",
    "        y = self.relu3.forward(self.conv3.forward(y))\n",
    "        y = self.flatten.forward(y)     # Flatten\n",
    "        y = self.relu4.forward(self.fc1.forward(y))\n",
    "        y = self.fc2.forward(y)\n",
    "        return y\n",
    "        \n",
    "        \n",
    "    def backward(self, loss):\n",
    "        grad = self.fc2.backward(loss)\n",
    "        grad = self.relu4.backward(grad)\n",
    "        grad = self.fc1.backward(grad)\n",
    "        grad = self.flatten.backward(grad)\n",
    "        grad = self.relu3.backward(grad)\n",
    "        grad = self.conv3.backward(grad)\n",
    "        grad = self.pool2.backward(grad)\n",
    "        grad = self.relu2.backward(grad)\n",
    "        grad = self.conv2.backward(grad)\n",
    "        grad = self.pool1.backward(grad)\n",
    "        grad = self.relu1.backward(grad)\n",
    "        grad = self.conv1.backward(grad)\n",
    "        return grad\n",
    "    \n",
    "    def train(self, X_train, y_train, epochs, batch_size, lr=0.001):\n",
    "        optimizer = Adam_opt(lr)        \n",
    "        loss_func = CategoricalCrossentropy()\n",
    "        \n",
    "        n_batches = X_train.shape[0] // batch_size\n",
    "        print(n_batches)\n",
    "\n",
    "        arr_train_loss = []\n",
    "        arr_train_acc = []\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for epoc in range(epochs):\n",
    "            print(epoc)\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "            \n",
    "            for i in tqdm.tqdm(range(n_batches)):\n",
    "\n",
    "                x_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "                y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "                # Forward pass\n",
    "#                 print(\"Forward\")\n",
    "                out = self.forward(x_batch)\n",
    "                loss = loss_func(out, y_batch)\n",
    "\n",
    "                # Backward pass\n",
    "#                 grad = softmax_cross_entropy(out, y_batch)\n",
    "#                 print(\"Backward\")\n",
    "#                 grad = loss_func.backward(out, y_batch)\n",
    "                grad = out - y_batch\n",
    "                self.backward(grad)\n",
    "\n",
    "                # Update weights\n",
    "#                 optimizer.update(self.conv_layers, self.fc_layers)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                pred = np.argmax(out, axis=1)\n",
    "                acc = np.mean(pred == np.argmax(y_batch, axis=1))\n",
    "\n",
    "                train_loss += loss\n",
    "                train_acc += acc\n",
    "\n",
    "            train_loss /= n_batches\n",
    "            train_acc /= n_batches\n",
    "\n",
    "            arr_train_loss.append(train_loss)\n",
    "            arr_train_acc.append(train_acc)\n",
    "\n",
    "        return arr_train_loss, arr_train_acc\n",
    "    \n",
    "    def predict(self, X_test, y_test):\n",
    "        \n",
    "        y_pred = self.forward(X_test)\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "        num_classes = len(np.unique(y_true))\n",
    "        total = np.zeros(num_classes)\n",
    "        correct = np.zeros(num_classes)\n",
    "\n",
    "        for i in range(len(y_test)):\n",
    "            true_label = y_test[i]\n",
    "            pred_label = y_pred_labels[i]\n",
    "            total[true_label] += 1\n",
    "            if (true_label == pred_label):\n",
    "                correct[true_label] += 1\n",
    "\n",
    "        class_acc = {}\n",
    "        for i in range(num_classes):\n",
    "            if total[i] == 0:\n",
    "                class_acc[i] = 0.0\n",
    "            else:\n",
    "                class_acc[i] = correct[i] / total[i]\n",
    "\n",
    "        return class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d248a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d1b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = np.reshape(Xtr, (-1, 3, 32, 32))[0:100]\n",
    "Xtr = np.transpose(Xtr, (0, 2, 3, 1))[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da326489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 32, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69bc950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c23648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical2one_hot(y: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    :param y - categorical array with (n, 1) shape\n",
    "    :return one hot array with (n, k) shape\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    one_hot_matrix = np.zeros((y.size, y.max() + 1))\n",
    "    one_hot_matrix[np.arange(y.size), y] = 1\n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2de165a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = convert_categorical2one_hot(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9890a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  8.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:17<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:20<00:00, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([18.766169072431282,\n",
       "  18.728615198320497,\n",
       "  18.711270391114105,\n",
       "  17.869658173393606,\n",
       "  17.437949437940002,\n",
       "  16.608729302886175,\n",
       "  16.5561472275392,\n",
       "  16.100467549206492,\n",
       "  15.673703895872347,\n",
       "  14.857180472550588,\n",
       "  14.440469137551721,\n",
       "  13.938063930255161,\n",
       "  13.089683409355555,\n",
       "  13.034285736637287,\n",
       "  12.996002687182246,\n",
       "  12.965142169174149,\n",
       "  12.548349422401643,\n",
       "  12.11609784392467,\n",
       "  11.67786434706439,\n",
       "  11.643396633138089,\n",
       "  11.617395637035449,\n",
       "  11.195445032366623,\n",
       "  10.778855832538099,\n",
       "  10.348731917689681,\n",
       "  9.932307324287049,\n",
       "  9.88979148410112,\n",
       "  9.86359466982842,\n",
       "  9.842259357182707,\n",
       "  9.823796975468712,\n",
       "  9.407408545156649,\n",
       "  9.384369286612419,\n",
       "  8.97359192500333,\n",
       "  8.947759147128725,\n",
       "  8.928501418849827,\n",
       "  8.911954759081091,\n",
       "  8.897333258169898,\n",
       "  8.494328151780703,\n",
       "  8.473282975446578,\n",
       "  8.457001580283656,\n",
       "  8.442898223534467,\n",
       "  8.43015920807994,\n",
       "  8.418456789578741,\n",
       "  8.407564738335884,\n",
       "  8.397305071662535,\n",
       "  8.387594653634977,\n",
       "  8.378369748026394,\n",
       "  7.5849847042789245,\n",
       "  7.55977993821964,\n",
       "  7.160013903729334,\n",
       "  7.125596860740373,\n",
       "  7.107367846772029,\n",
       "  7.092692344940453,\n",
       "  7.079924641089287,\n",
       "  7.068429480793961,\n",
       "  7.057959672425254,\n",
       "  7.048199164414379,\n",
       "  7.03899243917217,\n",
       "  7.030287349638723,\n",
       "  7.022007995808485,\n",
       "  6.620616424692906,\n",
       "  6.605119113819384,\n",
       "  6.208676643028079,\n",
       "  6.189150713316812,\n",
       "  6.175421365475014,\n",
       "  6.163945477958814,\n",
       "  6.153784022325354,\n",
       "  5.771142984542871,\n",
       "  5.743566584808937,\n",
       "  5.729472242812159,\n",
       "  5.71817360263093,\n",
       "  5.70829138371408,\n",
       "  5.6993299800660076,\n",
       "  5.691039015973857,\n",
       "  5.683272998384453,\n",
       "  5.67594236918765,\n",
       "  5.668983256604717,\n",
       "  5.66238084823259,\n",
       "  5.656048630711433,\n",
       "  5.64996386683778,\n",
       "  5.644102578663718,\n",
       "  5.638444906951772,\n",
       "  5.632981207311632,\n",
       "  5.6277021011525985,\n",
       "  5.622583132421557,\n",
       "  5.61761345486269,\n",
       "  5.61280272103995,\n",
       "  5.608114425174965,\n",
       "  5.603552248383865,\n",
       "  5.599104069177807,\n",
       "  5.232825314378972,\n",
       "  5.20681574720561,\n",
       "  5.196326564844514,\n",
       "  5.188428269156468,\n",
       "  5.1817007069106085,\n",
       "  5.175663392960784,\n",
       "  4.787812200224148,\n",
       "  4.770002884341544,\n",
       "  4.759711475602792,\n",
       "  4.751548304374723,\n",
       "  4.388148471694667],\n",
       " [0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.09,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.1,\n",
       "  0.11,\n",
       "  0.13,\n",
       "  0.13,\n",
       "  0.14,\n",
       "  0.14,\n",
       "  0.14,\n",
       "  0.14,\n",
       "  0.14,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.16,\n",
       "  0.15000000000000002,\n",
       "  0.15000000000000002,\n",
       "  0.16,\n",
       "  0.16,\n",
       "  0.16,\n",
       "  0.17,\n",
       "  0.17,\n",
       "  0.18,\n",
       "  0.18,\n",
       "  0.19,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.21000000000000002,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.19,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.21000000000000002,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23,\n",
       "  0.23])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(Xtr, y_train, 100, 50, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6beed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50a8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec40787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e9cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ead63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a1d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874f0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a48ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax_accuracy(y_hat: np.array, y: np.array) -> float:\n",
    "#     \"\"\"\n",
    "#     :param y_hat - 2D one-hot prediction tensor with shape (n, k)\n",
    "#     :param y - 2D one-hot ground truth labels tensor with shape (n, k)\n",
    "#     ----------------------------------------------------------------------------\n",
    "#     n - number of examples in batch\n",
    "#     k - number of classes\n",
    "#     \"\"\"\n",
    "#     y_hat = convert_prob2one_hot(y_hat)\n",
    "#     return (y_hat == y).all(axis=1).mean()\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(y_hat, y, eps=1e-20) -> float:\n",
    "    \"\"\"\n",
    "    :param y_hat - 2D one-hot prediction tensor with shape (n, k)\n",
    "    :param y - 2D one-hot ground truth labels tensor with shape (n, k)\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    n = y_hat.shape[0]\n",
    "    return - np.sum(y * np.log(np.clip(y_hat, eps, 1.))) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465a8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass output:\n",
      " (1, 4, 4, 1)\n",
      "Backward pass output:\n",
      " (1, 5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(1,5,5,3)\n",
    "k = np.random.randn(2,2,3,1)\n",
    "\n",
    "conv_layer = Conv2D(in_channels=3, out_channels=1, kernel_size=2, stride=1, padding=0)\n",
    "# conv_layer.w = k\n",
    "output_matrix = conv_layer.forward(a)\n",
    "print(\"Forward pass output:\\n\", output_matrix.shape)\n",
    "d_output_matrix = np.ones((1,4,4,1))\n",
    "d_input_matrix = conv_layer.backward(d_output_matrix, lr=0.001)\n",
    "print(\"Backward pass output:\\n\", d_input_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "089e6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass output:\n",
      " (1, 4, 4, 2)\n",
      "Backward pass output:\n",
      " (1, 8, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(1,8,8,2)\n",
    "k = np.random.randn(2,2,3,1)\n",
    "\n",
    "pool = MaxPool2D(2)\n",
    "# conv_layer.w = k\n",
    "output_matrix = pool.forward(a)\n",
    "print(\"Forward pass output:\\n\", output_matrix.shape)\n",
    "d_output_matrix = np.ones((1,4,4,2))\n",
    "d_input_matrix = pool.backward(d_output_matrix)\n",
    "print(\"Backward pass output:\\n\", d_input_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    To implement CNN following functions will be needed\n",
    "        1. Conv2D\n",
    "            a. forward\n",
    "            b. backward\n",
    "            c. update weights\n",
    "            d. get gradients\n",
    "        2. MaxPool\n",
    "            a. forward\n",
    "            b. backward\n",
    "        3. ReLU\n",
    "            a. forward\n",
    "            b. backward\n",
    "        4. Softmax\n",
    "            a. forward\n",
    "            b. backward\n",
    "        5. Full connected NN\n",
    "            a. forward\n",
    "            b. backward\n",
    "            c. update wights\n",
    "            d. get gradients\n",
    "        6. Adam optimizers(to update weights)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "    class ConvNet will include\n",
    "        1. forward\n",
    "        2. backward\n",
    "        3. train\n",
    "        4. predict\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
